<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Cross-validation</title>
<style type="text/css">
/**
 * Prism.s theme ported from highlight.js's xcode style
 */
pre code {
  padding: 1em;
}
.token.comment {
  color: #007400;
}
.token.punctuation {
  color: #999;
}
.token.tag,
.token.selector {
  color: #aa0d91;
}
.token.boolean,
.token.number,
.token.constant,
.token.symbol {
  color: #1c00cf;
}
.token.property,
.token.attr-name,
.token.string,
.token.char,
.token.builtin {
  color: #c41a16;
}
.token.inserted {
  background-color: #ccffd8;
}
.token.deleted {
  background-color: #ffebe9;
}
.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
  color: #9a6e3a;
}
.token.atrule,
.token.attr-value,
.token.keyword {
  color: #836c28;
}
.token.function,
.token.class-name {
  color: #DD4A68;
}
.token.regex,
.token.important,
.token.variable {
  color: #5c2699;
}
.token.important,
.token.bold {
  font-weight: bold;
}
.token.italic {
  font-style: italic;
}
</style>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
  box-sizing: border-box;
}
body, .footnotes, code { font-size: .9em; }
li li { font-size: .95em; }
*, *:before, *:after {
  box-sizing: inherit;
}
pre, img { max-width: 100%; }
pre, pre:hover {
  white-space: pre-wrap;
  word-break: break-all;
}
pre code {
  display: block;
  overflow-x: auto;
}
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class] { background-color: #F8F8F8; }
code.language-undefined, pre > code:not([class]) {
  background-color: inherit;
  border: 1px solid #eee;
}
table {
  margin: auto;
  border-top: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color: #666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC .numbered li { list-style: none; }
#TOC .numbered { padding-left: 0; }
#TOC .numbered ul { padding-left: 1em; }
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.footnote-ref a::before { content: "["; }
.footnote-ref a::after { content: "]"; }
section.footnotes::before {
  content: "";
  display: block;
  max-width: 20em;
}

@media print {
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  pre { white-space: pre; }
}
</style>
</head>
<body>
<div class="frontmatter">
<div class="title"><h1>Cross-validation</h1></div>
<div class="author"><h2></h2></div>
<div class="date"><h3></h3></div>
</div>
<div class="body">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
<h3 id="definition">✘ Definition</h3>
<p>Whether independent data is available or not, <strong>data-splitting</strong> methods allow to divide input data into pieces to <strong>calibrate</strong> and <strong>validate</strong> the models on different parts.</p>
<p>Most common procedures either split randomly the original dataset in two parts (<strong>random</strong>) with higher proportion to calibrate the models ; or in k datasets of equal sizes (<strong>k-fold</strong>), each of them being used in turn to validate the model, while the remaining is used for calibration. For both methods, the splitting can be repeated several times.<br />
Other procedures are available to test for model overfitting and to assess transferability either in geographic or environmental space : <strong>block</strong> method described in <em>Muscarella et al. 2014</em> partitions data in four bins of equal size (bottom-left, bottom-right, top-left and top-right), while <strong>x-y-stratification</strong> described in <em>Wenger and Olden 2012</em> uses k partitions along the x-(or y-) gradient and returns 2k partitions ; <strong>environmental</strong> partitioning returns k partitions for each environmental variable provided.<br />
These methods can be balanced over presences or absences to ensure equal distribution over space, especially if some data is clumped on an edge of the study area.<br />
The user can also define its own data partitioning (<strong>user.defined</strong>).</p>
<div style="text-align:center;">
<p><img src="pictures/CVschema.png" alt="Cross-validation Picture Summary" style="width:600px;"></p>
</div>
</br>
<h3 id="how-you-can-select-methods">✠ How you can select methods</h3>
<p><code>biomod2</code> allows you to use different strategies to separate your data into a calibration dataset and a validation dataset for the cross-validation. With the argument <code>CV.strategy</code> in <a href="../reference/BIOMOD_.html"><code>BIOMOD_Modeling</code></a>, you can select :
<br/></p>
<dl>
<dt>Random</dt>
<dd>The most simple method to calibrate and validate a model is to split the original dataset in two datasets : one to calibrate the model and the other one to validate it. The splitting can be repeated `nb.rep` times. You can adjust the size of the splitting between calibration and validation with `perc`.</dd>
<dt>K-fold</dt>
<dd>The `k-fold` method splits the original dataset in `k` datasets of equal sizes : each part is used successively as the validation dataset while the other `k-1` parts are used for the calibration, leading to `k` calibration/validation ensembles. This multiple splitting can be repeated `nb.rep` times.</dd>
<dt>Block</dt>
<dd>It may be used to test for model overfitting and to assess transferability in geographic space. `block` stratification was described in *Muscarella et al. 2014* (see References). Four bins of equal size are partitioned (bottom-left, bottom-right, top-left and top-right).</dd>
<dt>Stratified</dt>
<dd>It may be used to test for model overfitting and to assess transferability in geographic space. `x` and `y` stratification was described in *Wenger and Olden 2012* (see References). `y` stratification uses `k` partitions along the y-gradient, `x` stratification does the same for the x-gradient. both returns `2k` partitions: `k` partitions stratified along the x-gradient and `k` partitions stratified along the y-gradient.
You can choose `x`, `y` and `both` stratification with the argument `strat`. </dd>
<dt>Environmental</dt>
<dd>It may be used to test for model overfitting and to assess transferability in environmental space. It returns `k` partitions for each variable given in `env.var`.You can choose if the presences or the absences are balanced over the partitions with `balance`.</dd>
<dt>User-defined</dt>
<dd>Allow the user to give its own cross-validation table. For a presence-absence dataset, column names must be formatted as: `_allData_RUNx` with `x` an integer. For a presence-only dataset for which several pseudo-absence dataset were generated, column names must be formatted as: `_PAx_RUNy` with `x` an integer and `PAx` an existing pseudo-absence dataset and `y` an integer</dd>
<br> 
<fieldset>
_If you are ensure about the strategy and want to make verification, [`get_calib_lines()`](../reference/getters.out.html) can help you to visualize the split. (`TRUE` for calibration and `FALSE` for validation)_
</fieldset>
</br>
<h3 id="evaluation_1">✣ Evaluation</h3>
<p><code>biomod2</code> allows to use a cross-validation method to build (<strong>calibration</strong>) and validate (<strong>validation</strong>) the model, but it can also be tested on another independent dataset if available (<strong>evaluation</strong>). This second independent dataset can be integrated with the <code>eval.resp</code>, <code>eval.xy</code> and <code>eval.env.data</code> parameters in the <a href="../reference/BIOMOD_FormatingData.html"><code>BIOMOD_FormatingData</code></a> function.</p>
<br>
<fieldset>
_For example :_ 
<ul>
<li><em><em>dataset 1</em> will be used to build the individual models,</em>
<em>being split for instance 10 times into 70/30 percentages to cross-validate them.</em></li>
<li><em><em>dataset 2</em> will be used to evaluate all models (individual or ensemble).</em></li>
</ul>
</fieldset>
</br>
<p><strong>Note that</strong>, if you can have as many <em>evaluation</em> values (with <em>dataset 2</em>) as your number of cross-validation splitting for single models, you can have only one <em>evaluation</em> value for ensemble models.</p>
<p>This can be circumvented by using <code>em.by = 'PA+run'</code> within the <a href="../reference/BIOMOD_EnsembleModeling.html"><code>BIOMOD_EnsembleModeling</code></a> function to build for each cross-validation fold an ensemble model across algorithms.
You will obtain as many ensemble models as cross-validation split, and thus as many <em>evaluation</em> values. But you will also have several ensemble models, which may defeat your purpose of having a final single model.</p>
</br>
<h3 id="concretely">✜ Concretely</h3>
<p><em>All the examples are made with the data of the package.</em> <br/>
<em>For the beginning of the code, see the <a href="examples_1_mainFunctions.html">main functions vignette</a>.</em></p>
<h4 id="cross-validation">⛒ Cross-validation</h4>
<p>To do a random cross-validation method with 2 runs and with a distribution 80/20 for calibration and validation.</p>
<pre><code class="language-R">myBiomodModelOut &lt;- BIOMOD_Modeling(bm.format = myBiomodData,  
                                    modeling.id = 'Example',  
                                    models = c('RF', 'GLM'),  
                                    CV.strategy = 'random',  
                                    CV.nb.rep = 2,  
                                    CV.perc = 0.8,  
                                    metric.eval = c('TSS','ROC'))
</code></pre>
<br/>
<p>To get the cross-validation table and visualize it on your <a href="https://biomodhub.github.io/biomod2/reference/BIOMOD.formated.data.html"><code>BIOMOD.formated.data</code></a> or <a href="https://biomodhub.github.io/biomod2/reference/BIOMOD.formated.data.PA.html"><code>BIOMOD.formated.data.PA</code></a> object.</p>
<pre><code class="language-R">myCalibLines &lt;- get_calib_lines(myBiomodModelOut)
plot(myBiomodData, calib.lines = myCalibLines)
</code></pre>
<div style="text-align:center;">
<p><img src="pictures/MyBiomodData_With_CalibLines.png" alt="Visualization of the data with the different runs" style="width:750px;"></p>
</div>
</br>
To create a cross-validation table with [`bm_CrossValidation`](../reference/bm_CrossValidation.html). 
<pre><code class="language-R">bm_CrossValidation(bm.format = myBiomodData,
                   strategy = &quot;strat&quot;,
                   k = 2,
                   balance = &quot;presences&quot;,
                   strat = &quot;x&quot;)
</code></pre>
<br/>
<p>Example of a table for the <code>user.defined</code> method : <code>myCVtable</code>.</p>
<table>
<thead>
<tr>
<th>_PA1_RUN1</th>
<th>_PA1_RUN2</th>
<th>_PA2_RUN1</th>
<th>_PA2_RUN2</th>
</tr>
</thead>
<tbody>
<tr>
<td>FALSE</td>
<td>FALSE</td>
<td>FALSE</td>
<td>TRUE</td>
</tr>
<tr>
<td>TRUE</td>
<td>TRUE</td>
<td>FALSE</td>
<td>FALSE</td>
</tr>
<tr>
<td>TRUE</td>
<td>TRUE</td>
<td>TRUE</td>
<td>TRUE</td>
</tr>
<tr>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<pre><code class="language-R">myBiomodModelOut &lt;- BIOMOD_Modeling(bm.format = myBiomodData,  
                                    modeling.id = 'Example',  
                                    models = c('RF', 'GLM'),  
                                    CV.strategy = 'user.defined',  
                                    CV.user.table = myCVtable,
                                    metric.eval = c('TSS','ROC'))
</code></pre>
<br/>
<p><em>You can find more examples in the <a href="examples_2_secundaryFunctions.html">Secondary functions vignette</a>.</em></p>
<br/>
<h4 id="evaluation_2">☒ Evaluation</h4>
<p>To add an independent dataset for evaluation, you will need to provide the correspondent environment variable (<code>myEvalExpl</code>) as a raster, a matrix or a data.frame.</p>
<br/>
<p><em>Case 1</em> : If your evaluation response (<code>myEvalResp</code>) is a raster :</p>
<pre><code class="language-R">myBiomodData &lt;- BIOMOD_FormatingData(resp.var = myResp,
                                     expl.var = myExpl,
                                     resp.xy = myRespXY,
                                     resp.name = myRespName, 
                                     eval.resp.var = myEvalResp,
                                     eval.expl.var = myEvalExpl)
</code></pre>
<br/>
<p><em>Case 2</em> : If your evaluation response (<code>myEvalResp</code>) is a vector :</p>
<ul>
<li>you also need the coordinates of your response points : <code>myEvalCoord</code></li>
<li>if <code>myEvalExpl</code> is a data.frame or a matrix, be sure the points are in the same order.</li>
</ul>
<pre><code class="language-R">myBiomodData &lt;- BIOMOD_FormatingData(resp.var = myResp,
                                     expl.var = myExpl,
                                     resp.xy = myRespXY,
                                     resp.name = myRespName, 
                                     eval.resp.var = myEvalResp,
                                     eval.expl.var = myEvalExpl,
                                     eval.resp.xy = myEvalCoord)                                    
</code></pre>
</br>
<h3 id="references">✖ References</h3>
<ul>
<li>
<p><strong>Wenger, S.J.</strong> and <strong>Olden, J.D.</strong> (<strong>2012</strong>), <em>Assessing transferability of ecological models: an underappreciated aspect of statistical validation.</em> Methods in Ecology and Evolution, 3: 260-267. <a href="https://doi.org/10.1111/j.2041-210X.2011.00170.x">https://doi.org/10.1111/j.2041-210X.2011.00170.x</a></p>
</li>
<li>
<p><strong>Muscarella, R.</strong>, Galante, P.J., Soley-Guardia, M., Boria, R.A., Kass, J.M., Uriarte, M. and Anderson, R.P. (<strong>2014</strong>), <em>ENMeval: An R package for conducting spatially independent evaluations and estimating optimal model complexity for Maxent ecological niche models.</em> Methods in Ecology and Evolution, 5: 1198-1205. <a href="https://doi.org/10.1111/2041-210X.12261">https://doi.org/10.1111/2041-210X.12261</a></p>
</li>
</ul>
</div>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
</body>
</html>
